{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Architectures Assignment 1\n",
        "## Assignment 1 - Feed Forward neural network\n",
        "The goal is define neural network, write code for forward and backward pass, training loop and perform training.\n",
        "\n",
        "## TODO:\n",
        "1. Define feed forward neural network:\n",
        "    *   Define at at least 2 hidden layers.\n",
        "    *   At least 10 neurons.\n",
        "    *   At least one layer with ReLU activation function: **`relu(x) = max(0,x)`**.\n",
        "    *   Output layer with Sigmoid activation function.\n",
        "    *   Loss function should use (binary) cross entropy function.\n",
        "    *   Optimization should use batch gradient descent (gradient computed for entire training set).\n",
        "    *   All should be written using Numpy only.\n",
        "2. Draw computation graph of the network.\n",
        "\n",
        "##Notes:\n",
        "Please note that example code included with Logistic Regression using convension where batch dimension is the last one: X vector is defineds as [features, batch] where code here uses convention used by most of the frameworks whebe batch dimension comes first [batch, features]."
      ],
      "metadata": {
        "id": "JhsccDDlxnas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRtljaWrxftt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def download_dataset(file_id):\n",
        "  filename = f\"dataset{file_id}.h5\"\n",
        "  base_url = f\"https://github.com/pa-k/AGU/blob/main/assignment1/{filename}?raw=true\"\n",
        "  url = urlopen(base_url)\n",
        "  binary_data = url.read()\n",
        "  with open(filename,\"wb\") as f:\n",
        "    f.write(binary_data)\n",
        "\n",
        "def import_dataset(file_id):\n",
        "  filename = f\"dataset{file_id}.h5\"\n",
        "  if not os.path.exists(filename):\n",
        "    download_dataset(file_id)\n",
        "  fp = h5py.File(filename, \"r\")\n",
        "  x_train = np.array(fp[\"x_train\"][:])\n",
        "  y_train = np.array(fp[\"y_train\"][:])\n",
        "  x_test = np.array(fp[\"x_test\"][:])\n",
        "  y_test = np.array(fp[\"y_test\"][:])\n",
        "  fp.close()\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "student_id = 123456     #Your id\n",
        "file_id = student_id%17\n",
        "\n",
        "x_train, y_train, x_test, y_test = import_dataset(file_id)\n",
        "\n",
        "assert x_train.shape == (600, 32, 32, 3)\n",
        "assert x_test.shape == (200, 32, 32, 3)\n",
        "assert y_train.shape == (600, 1)\n",
        "assert y_test.shape == (200, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample image"
      ],
      "metadata": {
        "id": "8Ii9D0rl1Kai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = random.randint(0,x_train.shape[0]-1)\n",
        "plt.axis('off')\n",
        "plt.imshow(x_train[index])\n",
        "print(\"Label: \" + str(y_train[index]))"
      ],
      "metadata": {
        "id": "NdOqH_Bvxsjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Flatten and normalize data"
      ],
      "metadata": {
        "id": "CXIRM7g31OvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1)/255\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)/255"
      ],
      "metadata": {
        "id": "tFsYa1mKxulP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Dimensions"
      ],
      "metadata": {
        "id": "JXhKHJcm1Pce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Dataset dimensions:\")\n",
        "print (\"Number of training examples: m_train = \" + str(x_train.shape[1]))\n",
        "print (\"Number of testing examples: m_test = \" + str(x_test.shape[1]))\n",
        "print (\"train_x shape: \" + str(x_train.shape))\n",
        "print (\"train_y shape: \" + str(y_train.shape))\n",
        "print (\"test_x shape: \" + str(x_test.shape))\n",
        "print (\"test_y shape: \" + str(y_test.shape))"
      ],
      "metadata": {
        "id": "g_e6PqU5xw8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Paste here diagram of the computation graph and indicate variables used in the propagate function"
      ],
      "metadata": {
        "id": "HHN7QjEF1jDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BAu4GDGq1puV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define forward and back propagation"
      ],
      "metadata": {
        "id": "gri1BnE91UUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(object):\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        input size - number of features of the input\n",
        "        \"\"\"\n",
        "        #Fix definition of weight matrices and biases, use np.random.uniform function\n",
        "        W1 = None\n",
        "        b1 = None\n",
        "        W2 = None\n",
        "        b2 = None\n",
        "\n",
        "        self.params = {'W1': W1,\n",
        "                       'b1': b1,\n",
        "                       'W2': W2,\n",
        "                       'b2': b2}\n",
        "        self.grads = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "    #write code to do prediction: for input set of images (dimension [batch,features]) it should set predictions vector [batch] indicatating image class\n",
        "\n",
        "        W1, b1 = self.params['W1'], self.params['b1']\n",
        "        W2, b2 = self.params['W2'], self.params['b2']\n",
        "\n",
        "\n",
        "        predictions = 0\n",
        "\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def propagate(self, X, y):\n",
        "        y = y.reshape(-1, 1)   #fix y vector to have shape [batch,1]\n",
        "        nbatch = y.shape[0]\n",
        "\n",
        "        W1, b1 = self.params['W1'], self.params['b1']\n",
        "        W2, b2 = self.params['W2'], self.params['b2']\n",
        "\n",
        "\n",
        "        #forward pass - you should at least calculate cost function (average loss for all examples in a batch)\n",
        "        cost = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #backward pass - get values of dW1, dW2,db1,db2\n",
        "        dW1 = None\n",
        "        dW2 = None\n",
        "        db1 = None\n",
        "        db2 = None\n",
        "\n",
        "\n",
        "\n",
        "        self.grads = {'dW1': dW1,\n",
        "                      'db1': db1,\n",
        "                      'dW2': dW2,\n",
        "                      'db2': db2}\n",
        "\n",
        "        return cost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def update(self, alpha):\n",
        "        #calculate new values of network parames (self.params) based on learning rate alpha and gradients (self.grads)\n",
        "\n",
        "        pass"
      ],
      "metadata": {
        "id": "G_h-X9rfxyDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train model"
      ],
      "metadata": {
        "id": "g_cB-kOl1Xyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.01\n",
        "net = NeuralNet(x_train.shape[1])\n",
        "for i in range(1000):\n",
        "    loss = net.propagate(x_train, y_train)\n",
        "    net.update(alpha)\n",
        "    if i % 100 == 0:\n",
        "        y_pred_train = net.predict(x_train)\n",
        "        y_pred_test = net.predict(x_test)\n",
        "        print(loss)\n",
        "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100))\n",
        "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_test - y_train)) * 100))"
      ],
      "metadata": {
        "id": "Un4Nf0PIx2H4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}