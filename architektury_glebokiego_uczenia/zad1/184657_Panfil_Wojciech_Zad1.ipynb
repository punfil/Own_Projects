{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhsccDDlxnas"
      },
      "source": [
        "#Deep Learning Architectures Assignment 1\n",
        "## Assignment 1 - Feed Forward neural network\n",
        "The goal is define neural network, write code for forward and backward pass, training loop and perform training.\n",
        "\n",
        "## TODO:\n",
        "1. Define feed forward neural network:\n",
        "    *   Define at at least 2 hidden layers.\n",
        "    *   At least 10 neurons.\n",
        "    *   At least one layer with ReLU activation function: **`relu(x) = max(0,x)`**.\n",
        "    *   Output layer with Sigmoid activation function.\n",
        "    *   Loss function should use (binary) cross entropy function.\n",
        "    *   Optimization should use batch gradient descent (gradient computed for entire training set).\n",
        "    *   All should be written using Numpy only.\n",
        "2. Draw computation graph of the network.\n",
        "\n",
        "##Notes:\n",
        "Please note that example code included with Logistic Regression using convension where batch dimension is the last one: X vector is defineds as [features, batch] where code here uses convention used by most of the frameworks whebe batch dimension comes first [batch, features]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uRtljaWrxftt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def download_dataset(file_id):\n",
        "  filename = f\"dataset{file_id}.h5\"\n",
        "  base_url = f\"https://github.com/pa-k/AGU/blob/main/assignment1/{filename}?raw=true\"\n",
        "  url = urlopen(base_url)\n",
        "  binary_data = url.read()\n",
        "  with open(filename,\"wb\") as f:\n",
        "    f.write(binary_data)\n",
        "\n",
        "def import_dataset(file_id):\n",
        "  filename = f\"dataset{file_id}.h5\"\n",
        "  if not os.path.exists(filename):\n",
        "    download_dataset(file_id)\n",
        "  fp = h5py.File(filename, \"r\")\n",
        "  x_train = np.array(fp[\"x_train\"][:])\n",
        "  y_train = np.array(fp[\"y_train\"][:])\n",
        "  x_test = np.array(fp[\"x_test\"][:])\n",
        "  y_test = np.array(fp[\"y_test\"][:])\n",
        "  fp.close()\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "student_id = 184657     #Your id\n",
        "file_id = student_id%17\n",
        "\n",
        "x_train, y_train, x_test, y_test = import_dataset(file_id)\n",
        "\n",
        "assert x_train.shape == (600, 32, 32, 3)\n",
        "assert x_test.shape == (200, 32, 32, 3)\n",
        "assert y_train.shape == (600, 1)\n",
        "assert y_test.shape == (200, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ii9D0rl1Kai"
      },
      "source": [
        "#Sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NdOqH_Bvxsjs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: [0.]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXt0lEQVR4nO3cuXNcB3bF4fvW3hsAAZKSRlPayp4JHNhy4Cr/03Y5cODADlwOvZUkUjOaEUmRBIm90UB3v36rA9o31T1VZNly/b741sXDW/p0B+8kwzAMBgCAmaX/2wcAAPi/g1AAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAy6ODb968lRbXdR2eHU8m0m7rmvBolmu5t6l2wnFo7/2NijI8e3RyIu1OEmnc+r4Nzw7WS7uHNr47TcK3oJmZJcI/WrdbaXdbd9J8WYzDs2mq3YfK9UzE3X0vXM9BOyft7j48++qn59LunXh9Fg8eh2cffvKptFt55zfrtc+Ju/U6PHt+dSnt/ouv//JnZ/ilAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAAFy6eefbsR2nx82cvwrPLxaG0e5THu1vGk0za3Vi8p2S3jfe8mJmVWfxYvvrT30q75/O5NN+0+/Bs32mdM9Vd/LxMRlNptwnXZ73WemEuL8+l+fl0GZ49OXkk7W6Enp+iLKTdd/e34dl6L3SBmdnqMn7Onzx5Ku3e99p32F99/ifh2U8ur6XdqcXLqdK2knb/3d/+TXj2P588kXb//T/808/O8EsBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgAvXXOz3W2nx3Tr+2niZxV8ZNzPb1nfh2YPDhbT70y++DM/2fbzmwMysFaolNusbafe4FOs8mvir9/tKe00/S+LfNcpC+16y3cSvfTY00u5x+Gl4Z+jj56WttUqUoY8/E12r/Z9dG3+W62ot7T47Pw3PbjbaZ8pk+UCaz4Rame39RtpdpPHdzWYl7f7oo3glSi1W0ETwSwEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAC7c9vLZ57/WFqdtePZoOZd2v/3px/Ds8fGBtHs2noVnu0HrHWnreLlOKvQHmZnVu512LEJfTteIHUIzoW8q1XqvhqEPz2Zip5YlgzQ+mU3Cs+uN1iFUFkV8Nh1Ju83i921v8efYzOxuG+94ykfx82dmluVaOVWWx/uJcqEnycwsG+L31jCeSru//qu/Ds9+ebOSdkfwSwEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAC783PhmLr9L3dXi0qeOvxpuZnZzEqysS06oLbm+uw7PxwoV3unYfnp1NtFfjpxPt+oyKcXg2E6sokixe0TCkWr3AkAj1AuJxd+IFHQv1BX2v3ePr+5vw7KDd4rbbbsOzbVdJu2/v78KzXa/VXIxMu56pMK9+Tgx9/GZJC+3ZPH78cXj25jZ+vqP4pQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAABfuPuqqeJeRmVm7jff8JEIPj5nZeHIUnm0a7bi7fhee3W213pH9vgnPJl38fzQzm4y1Xph+6OKzvbY7H83Ds0mqfS/pk3hHTS925YxKraNmv9mEZ4e+lXYrhUbq7vk03k11dnYh7a528Y6n5dEDafdiGe88MzMr8niv1tCJn29CVdJ8OpN2f/zJr8Kzr16+knZH8EsBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgAvXXKSJlh/jchqfHWmvgRdlGZ7NhFfdzcwGi9c/dF28EsPMbDyKH3dZxKsIzMx21Vaar+sqPLuvtBqFI+FeSXqt4qRv4sddV9r1qffaOVxdxysg5ouFtHt5EK902NzH6zbMzNpaOC9D+CPi3Xgfv/ZZpu1OxM+gQakKEWbV+aVYzzGfxT8Pe/G4I/ilAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAAFy4f6fpeWty2wvyg9ROZxfs+klTrBsmyeE7WdSPt3m3jnTOTUS3tHk+0rqTEkvBsU++l3Zvbs/DszYV2Dos8/n/OpiNpd1Nq35H6Pr6/FZ+fPI/vHk3i19LMbFTEe8mavbb7aLkKz+632j3ejLUOrl445x+y+6gQe8yyTP08fL/4pQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAhWsulFfGzcxubi7Ds21TSbtHs/hr42naSbsn00l4tuu03ft9/P+8eBuvijAza8RzuNlsw7NJor12n6XxY1kuH0i7v/jit+HZ8Xgu7U7S8ONgZmbTWbzqYFdplQ55MQ7PzoXaCjOzvo3ft02lPffHRw/Ds+c3a2n3MGjHojyf6ufbfh+vfunF407T+Hf1JNFqSEJ//71vBAD8YhEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAFy47EXp4zAzs6QNj97cvpVWH5fH4dl9vZN2V/v4/OHRkbR7t433Db16+ZO0uxxp/UQ3Qu9MYtrusoz3/JycfCLtnk7j5zzLFtLu8XgmzWd5vCup7a6l3f0QP+d9r3VwtXX82UwSrQ/qYLEMz66F/i0zs91Om+/7+L2idh8pn4d5pj0/imGI929F8UsBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAAAuXGzSd1q/SpbH+z7yYiztTpTeEXV3Fu966TqtL+X87E149vomPmtmNplMpPkyH4Vn81Trv1nM48fSVPGeJDOz9e1teHZbVdruu3gflJlZkiTh2V2ldXAVZSFMi8+mcD2LLH6fmJktj4U+sIszaXe91a7nIHRCqd1HJlx75T5Rj4XuIwDAB0UoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAXPh999GolBYfLOOvuydiNDXC6+vdoC3v+/j87e1G2n11dRkfTrTX7vu2lebHs1l4thSqP8zMylSoOEm1ioZXL38fnt3stAqNXmsjsM0ufv0PlgfS7sV0Gp5dr7V6jt7i16cYafUpf/bnX4dnJ4ultPvsXHh+zKwVnom2aaTdSs1FL3xemZkNQ/zZ78T6oQh+KQAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwIVLbardvbR4tb4Oz263WofQeDwPz5bCrJlZkRXxYaGjxMzs8mIVnq0rrW/o6OEDab5t4p0po0z77lCORuHZXVVJu5su3me0Wmv31XSu3SvKafno0eEH212WWq/SzWoXnn379o20++DF8/Bsvdeu/a7W+r22+3ifUVoIz72ZpRbvPhqGQdqdmDA/0H0EAPiACAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIALdync3d1Kiy/Oz8KzvfqqdhKvgGg7rS5ic3EVnu1qrUahzMfh2XyRSbs3mztp/mAxDc9OptqxtBa/nmPhnJiZbe7idSvr27W0e7ePV2iYmc3nZXi22mjH0vVCRYN4DkdlvNLh0YlWn/L8jz+EZ69X2j3btlpdRNPEz2Fda9d+6OLH0gmzZmapUnPRascd+/sAAPw3QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCACxcD5Xm8L8XMbBDqO/pe6wZZr+I9TOOxtvt+E+/WuTo/lXZPJqPwbKP2vOwraX46i1/PqdDxY2a2a/vw7MmjR9Lu1XoXP47dVtt9r3Xx5NlReLbaxu8rM7Oq3odnh1Trv0mG+PUcjbVepcUsPn99eSntru7i197MbHUV719LLX4tzcz28csjdx/ttvFOtR9/+F7aHcEvBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAAAuXHORplrNhVkmzGqvgSt2lVYvsNvF5/d7rUbhYH4Qnl0sj6XdyaC9pp/2bXj28OCxtPvjw1l8OFHuE7M8D9+yVu+1+odtrVWFtE38/2x2Qi+CmSnPTz9o57DI498Fd1vtHq+qeBXF8cFC2m2NNn7++ll4tqrW0u758pPwbCZWBG2EupVXP72QdkfwSwEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAC5cJNP14uYhiR9EIvYqZfGul02l9dk0TbwTqOs6aXfbxncfz8RemETL90yom5ovtF6lySJ+PTdbrRMoz8vwbNtq16eptHKd1IR7vNT6iUZl/Pqfnt1Ku2fTaXh2Oh1LuzdVvCtpdrSUdo9HE2m+eRl/9m9X2jncN/F7/Jv/+Ddpdy30tV1cr6TdEfxSAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAE7qPtPKjpq7Ds6kJRTxmprQZdWLuFeVImI338JiZ7et4z8/Qa51ABw8eSvOpxa/n1c1baXdexc/5ZKr1Ks2ETqjpdCbtvji/kOZ7ofvq+OEDaXfVCv1eW+369G38eav3d9LuJI9f+6qLd4GZmc3n8WfTzGw6j1//y9fn0u5NFb9X/uWf/1HarVjvtL6uCH4pAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHDhmovpbCotHk/iFRDnF6fS7nwyj8+W2nErr+kXI+21+66PF3Q0+620e32tncO6ug/P5plWcXKQxSs3ulx7Tb8o4tfnwfGhtPvZ83hthZnZ/X28AmIy1e7DrIvXXMxmE2l3s4vfW6O5VkEznsT/z32t3VfJoNViHB0tw7MvT7Wai32zC89m4lfvNAl/LNsgVK2E//573wgA+MUiFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAC4cMlGXdfS4rvtJjyblYW0O8vjvTCZWDxSV/EukdU63n1jZjYVqpLu1rfS7mTQrs9iEe+mWi4W2rEIlTar6ytpd7WPX5/xROumWh7Eu3LMzCxJwqNtF581M+uFyqGJ2H1kXbyDazbVjns6ij/LvXAtzcwm47E0P5och2fHk9fS7s1t/NkfBq0/KhE+snq6jwAAHxKhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcOGai67VXqeum/h8Vsyk3W0bf218tbrWdjfxjoaLq7W0++RoGp796tOH0u4y1a7PYhmvRkjTeK2Imdnd3S48W+0baXcxjh/3aKzVpxwcHkrzrfBMbLettHvfxe/xXKyJmR8ehGeHVDvuRHiWx3OhD8XMHj46keZ3+/h9m6daJUrbxGtothZ/HszMRmX82veddg4j+KUAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAAAX7j6aTOKdM+/m4/0qL1+/kXanaRKevby8lHav19vw7Nn5ubR76A7Ds1cPtfM9H2n9RGbxc9gn2u4iK8Oz81n4FjQzs0To+dkLHVlmZqdvtOs5E3qYbm8raXeXxK+P2tnU1PEunqHWOrXaJH7tDx9r93g/aNfz/PwqPLuvtI6nLI3/n32vncPdLn59ukbrDovglwIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAAF+4Y6Lr4a/dmZq9fxysD8mws7W6FV7vPTrWai90uXkeQxU+fmZldvL0Oz54da+dkN9Pmt/s+PDudz6TdDw7ix1JOtHNYjufh2W++fSLtrlvtO9KXv/48PCu2KNhqFb9vkyut/uF2Hb8P55P4+TYzO1jE5+tKq7modlqlw/e/exGe7Xtt91L5Pxvx4scfTUuTtbY7svO9bwQA/GIRCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAABcuHjm6dPvtcWl1sWjOH0R7zRJTOtsKssyPFtV8Z4kM7O7+2149vmLC2n30dFSms+L2/Dsb37zlbS7S7LwbFpMpd2bbbxH5sdnp9LuowcfSfOzgwfh2TfnV9Lus9evw7Onp6+k3atV/NqXRSHtVuYPluo9q/VkdUKHUDnV+r16oW5qGLTv3iPhszMv4p9XUfxSAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAODC740nqZYfTduEZ7978kTa3bXxqoNMPO6ui7+/nuTa7tnyKDy7WnfS7qvbc2l+sH14dnH0UNo9KuP1BdvdRtr9r//+TXj2m29/kHZ/+tln0vzJ4/h5efk8Xs1iZnZ2+iY8u9tqdSvHxyfh2U7pczCz89U6PLvt4vegmdnxA61yYzyO10W0Fq9mMTNrhc+JVDyHQx7v5+hN2x3BLwUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAALhw91Er9A2ZmX339Gl4Ni3Ch2FmZkMijUuKbBSezYdS2p0M8QxOE63npRN7ZOrmPjz7+z+8knbfXMb7jLpGu69enb4Nzx4cxjt+zMy2W+0cvnp5Gp69vo53ApmZWRq/t5aHU2n18ijeTZUV2j1++Ejoycq076STUusnSpL4B0Vv2odKlsY7h7Je252m8f8zSd//hyG/FAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4MKlQ99++622WajkKEZav0q8dcTMBmnasizeO5IK3SpmZolwUspU7T7S8n3cx/umuq6Rdq9ud+HZTOh5MTM7OHoUnj0UdytdOWZmg9Bp8+hx/LjNzFKpF6iTdudC1Vgv9HWZmeVKv1eqdZ4lQt+Qmdkw9PHhXpg1s1y4V3LhM+Wd+P+pHXUMvxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAuPB75vf399LiyWQSHxZfA8+L+OvxZa7VRaRpPCc79dX4VHg1XnlF38y6rtWORTjnWaJdn145L4lWdZDn8WOpm724W7tXlAaVQStnsX6IV4sk4le7blCen5G0Ox3i1ycRKzSGRKtbUb7ytr32/JjwfOaZVuOjlJYMYo1PBL8UAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgwiUos5HQZWRmpdCXk4v9N0kpdLeMtO6WTuioqVqti6Xv460mVas0oJj1QmeTmVmi9BmlWr/KMMQ7nrT/0iwROmrKTLuvMvEcKj1ZRar1R6VCT5Zaf5MI1yftteNOhCKmXuz3Snr1O6zwfwqzZmaZ0B3WCef73Xz8vCj3YHjne98IAPjFIhQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAAAu3AMwn8+kxaOiiB+EMGumv5Ku6IXdufCqu5lZI7y+Poh5XYxKaV55TV9sUbBOqPMYOq3qYKjjNRe5WC0xEitR8jJ+3ybiPdv3wr2i9lwIV7Rp4+fbTLv2akVDLtaWKJ8ruVpxItR5VPtK2t0r11O+9j+PXwoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHDhMpG6i3eamJlthL6PrG2k3YlQ99GLzT2J0IEypFqfTdPE/0+l+8ZM779Ruo86sf9GOXa1EyjN48fdir1KrdhRk3XCfStW1LTCM6Hcs2Zmg3B9pB4eMxv6+HxZan1daaZ9TuRdvCtJbVOTnrfkw/VeKZ8pUfxSAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAODC74F/97un0uI/PPsxPJul8eoCM7NB6QwQ6wWSLJ6Tifj6+od4Jf1/KLUVZtpr+qlYo6DMq/UcJsyru9V5taJDoRyL9DyYVqOg1FaYmSVC9Yv6/BR5Ic0rl0e9DT/kfaiclV6sH4rglwIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAFwyyOUzAID/r/ilAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcP8FEBnycmd1nQAAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "index = random.randint(0,x_train.shape[0]-1)\n",
        "plt.axis('off')\n",
        "plt.imshow(x_train[index])\n",
        "print(\"Label: \" + str(y_train[index]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXIRM7g31OvG"
      },
      "source": [
        "#Flatten and normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tFsYa1mKxulP"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1)/255\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXhKHJcm1Pce"
      },
      "source": [
        "#Dataset Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "g_e6PqU5xw8q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset dimensions:\n",
            "Number of training examples: m_train = 3072\n",
            "Number of testing examples: m_test = 3072\n",
            "train_x shape: (600, 3072)\n",
            "train_y shape: (600, 1)\n",
            "test_x shape: (200, 3072)\n",
            "test_y shape: (200, 1)\n"
          ]
        }
      ],
      "source": [
        "print (\"Dataset dimensions:\")\n",
        "print (\"Number of training examples: m_train = \" + str(x_train.shape[1]))\n",
        "print (\"Number of testing examples: m_test = \" + str(x_test.shape[1]))\n",
        "print (\"train_x shape: \" + str(x_train.shape))\n",
        "print (\"train_y shape: \" + str(y_train.shape))\n",
        "print (\"test_x shape: \" + str(x_test.shape))\n",
        "print (\"test_y shape: \" + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHN7QjEF1jDc"
      },
      "source": [
        "#Paste here diagram of the computation graph and indicate variables used in the propagate function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAu4GDGq1puV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gri1BnE91UUm"
      },
      "source": [
        "#Define forward and back propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "G_h-X9rfxyDt"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(object):\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        input size - number of features of the input\n",
        "        \"\"\"\n",
        "        #Fix definition of weight matrices and biases, use np.random.uniform function\n",
        "        # At least 10 neurons\n",
        "        self.neurons_cnt = 10\n",
        "        W1 = np.random.uniform(-0.1, 0.1, (input_size, self.neurons_cnt))\n",
        "        b1 = np.random.uniform(-0.1, 0.1, (1, self.neurons_cnt))\n",
        "        W2 = np.random.uniform(-0.1, 0.1, (self.neurons_cnt, 1))\n",
        "        b2 = np.random.uniform(-0.1, 0.1, (1, 1))\n",
        "\n",
        "        self.params = {'W1': W1,\n",
        "                       'b1': b1,\n",
        "                       'W2': W2,\n",
        "                       'b2': b2}\n",
        "        self.grads = {}\n",
        "\n",
        "\n",
        "    def cross_entropy(self, y, y_hat):\n",
        "        return -np.mean(y * np.log(y_hat) + (1-y) * np.log(1-y_hat))\n",
        "\n",
        "\n",
        "    def relu(self, z):\n",
        "        return np.maximum(z, 0)\n",
        "\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "    #write code to do prediction: for input set of images (dimension [batch,features]) it should set predictions vector [batch] indicatating image class\n",
        "\n",
        "        W1, b1 = self.params['W1'], self.params['b1']\n",
        "        W2, b2 = self.params['W2'], self.params['b2']\n",
        "\n",
        "        z1 = np.dot(X, W1) + b1\n",
        "        z2 = np.dot(self.relu(z1), W2) + b2\n",
        "        predictions = self.sigmoid(z2)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "    def propagate(self, X, y):\n",
        "        y = y.reshape(-1, 1)   #fix y vector to have shape [batch,1]\n",
        "        nbatch = y.shape[0]\n",
        "\n",
        "        W1, b1 = self.params['W1'], self.params['b1']\n",
        "        W2, b2 = self.params['W2'], self.params['b2']\n",
        "\n",
        "        #forward pass - you should at least calculate cost function (average loss for all examples in a batch)\n",
        "        m1 = np.dot(X, W1)\n",
        "        z1 = m1+b1\n",
        "        r = self.relu(z1)\n",
        "        m2 = np.dot(r, W2)\n",
        "        y_hat = self.sigmoid(m2+b2)\n",
        "        cost = self.cross_entropy(y=y, y_hat=y_hat)\n",
        "\n",
        "        #backward pass - get values of dW1, dW2,db1,db2\n",
        "        dy_hat = -y / y_hat + (1-y) / (1-y_hat)\n",
        "        dz2 = y_hat * (1-y_hat) * dy_hat\n",
        "        db2 = (1/nbatch) * np.sum(dz2, axis=0, keepdims=True)\n",
        "        dW2 = (1/nbatch) * np.dot(r.T, dz2)\n",
        "        dr = np.dot(dz2, W2.T)\n",
        "        dz1 = dr * (z1 > 0)\n",
        "        db1 = (1 / nbatch) * np.sum(dz1, axis=0, keepdims=True)\n",
        "        dW1 = (1 / nbatch) * np.dot(X.T, dz1)\n",
        "\n",
        "        self.grads = {'dW1': dW1,\n",
        "                      'db1': db1,\n",
        "                      'dW2': dW2,\n",
        "                      'db2': db2}\n",
        "\n",
        "        return cost\n",
        "\n",
        "\n",
        "    def update(self, alpha):\n",
        "        #calculate new values of network parames (self.params) based on learning rate alpha and gradients (self.grads)\n",
        "        self.params = {'W1': self.params[\"W1\"] - alpha * self.grads[\"dW1\"],\n",
        "                       'b1': self.params[\"b1\"] - alpha * self.grads[\"db1\"],\n",
        "                       'W2': self.params[\"W2\"] - alpha * self.grads[\"dW2\"],\n",
        "                       'b2': self.params[\"b2\"] - alpha * self.grads[\"db2\"]}\n",
        "\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_cB-kOl1Xyf"
      },
      "source": [
        "#Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Un4Nf0PIx2H4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.690635404857273\n",
            "train accuracy: 50.399956335823354 %\n",
            "test accuracy: 50.05532633614463 %\n",
            "0.6805237140991338\n",
            "train accuracy: 50.74930753577659 %\n",
            "test accuracy: 50.347803866321605 %\n",
            "0.667694138083107\n",
            "train accuracy: 51.490322864423 %\n",
            "test accuracy: 50.82867531574431 %\n",
            "0.6467614552255172\n",
            "train accuracy: 52.7855898787383 %\n",
            "test accuracy: 51.623733454135674 %\n",
            "0.6179098203893542\n",
            "train accuracy: 54.72709170693196 %\n",
            "test accuracy: 52.81298918993718 %\n",
            "0.5859104304420518\n",
            "train accuracy: 57.074077776263024 %\n",
            "test accuracy: 54.2526404151417 %\n",
            "0.5561880922648483\n",
            "train accuracy: 59.415541749125126 %\n",
            "test accuracy: 55.672424124652636 %\n",
            "0.5304556319951694\n",
            "train accuracy: 61.517293847825805 %\n",
            "test accuracy: 56.91086683389713 %\n",
            "0.508200007956908\n",
            "train accuracy: 63.339430401819676 %\n",
            "test accuracy: 57.94953572758867 %\n",
            "0.48838974496093956\n",
            "train accuracy: 64.91791289145667 %\n",
            "test accuracy: 58.77281991826909 %\n",
            "0.47092954919432023\n",
            "train accuracy: 66.29733459671633 %\n",
            "test accuracy: 59.42802022366921 %\n",
            "0.4539843670458273\n",
            "train accuracy: 67.54191691360356 %\n",
            "test accuracy: 59.905388175685836 %\n",
            "0.4378656227077405\n",
            "train accuracy: 68.77013702189886 %\n",
            "test accuracy: 60.37133235314211 %\n",
            "0.422580076368618\n",
            "train accuracy: 69.89857509767661 %\n",
            "test accuracy: 60.77724597367957 %\n",
            "0.40814616568499046\n",
            "train accuracy: 70.96566921799177 %\n",
            "test accuracy: 61.128998100874874 %\n",
            "0.3941722620015307\n",
            "train accuracy: 71.94034698183845 %\n",
            "test accuracy: 61.3620972130895 %\n",
            "0.38064876417551596\n",
            "train accuracy: 72.88733821279325 %\n",
            "test accuracy: 61.56888621040711 %\n",
            "0.36783881263010954\n",
            "train accuracy: 73.734353485163 %\n",
            "test accuracy: 61.708361226855814 %\n",
            "0.386609673816721\n",
            "train accuracy: 73.27095234150809 %\n",
            "test accuracy: 61.17836191123564 %\n",
            "0.37636202603103724\n",
            "train accuracy: 73.95681961365274 %\n",
            "test accuracy: 61.330837222067586 %\n",
            "0.37574311689333334\n",
            "train accuracy: 74.30563286339861 %\n",
            "test accuracy: 61.36170604437576 %\n",
            "0.362439552139422\n",
            "train accuracy: 75.0609861175528 %\n",
            "test accuracy: 61.55216009426369 %\n",
            "0.35548446949141727\n",
            "train accuracy: 75.58088832010728 %\n",
            "test accuracy: 61.65441309227741 %\n",
            "0.34942891484666216\n",
            "train accuracy: 76.14277393560525 %\n",
            "test accuracy: 61.77197212266073 %\n",
            "0.339977928019185\n",
            "train accuracy: 76.70932000264136 %\n",
            "test accuracy: 61.910158837804865 %\n",
            "0.3332677744487957\n",
            "train accuracy: 77.21958321434263 %\n",
            "test accuracy: 62.034535839813316 %\n",
            "0.32676911479788295\n",
            "train accuracy: 77.72694556750899 %\n",
            "test accuracy: 62.17600659631633 %\n",
            "0.32228798259462027\n",
            "train accuracy: 78.15231856232116 %\n",
            "test accuracy: 62.26454615614705 %\n",
            "0.3108124921318256\n",
            "train accuracy: 78.79544159394767 %\n",
            "test accuracy: 62.444791999819216 %\n",
            "0.29920511397205424\n",
            "train accuracy: 79.4416076283001 %\n",
            "test accuracy: 62.609602309877516 %\n",
            "0.29851736008121627\n",
            "train accuracy: 79.66770691113811 %\n",
            "test accuracy: 62.628604348822435 %\n",
            "0.3027067920367649\n",
            "train accuracy: 79.69685149274228 %\n",
            "test accuracy: 62.611042386293285 %\n",
            "0.3052991168192048\n",
            "train accuracy: 79.74995751466614 %\n",
            "test accuracy: 62.59097734189346 %\n",
            "0.286533079080344\n",
            "train accuracy: 80.5656165090849 %\n",
            "test accuracy: 62.78660946530012 %\n",
            "0.23663721088992426\n",
            "train accuracy: 82.93934841310269 %\n",
            "test accuracy: 63.44356922109214 %\n",
            "0.217973997345696\n",
            "train accuracy: 84.05201960280068 %\n",
            "test accuracy: 63.761692609595656 %\n",
            "0.2564981083449308\n",
            "train accuracy: 82.4747718507297 %\n",
            "test accuracy: 63.333004068443884 %\n",
            "0.21217987848249095\n",
            "train accuracy: 84.43374808050221 %\n",
            "test accuracy: 63.80208292487448 %\n",
            "0.25095731898019014\n",
            "train accuracy: 83.03570420643835 %\n",
            "test accuracy: 63.487509645966064 %\n",
            "0.20811301171264124\n",
            "train accuracy: 84.74808867401079 %\n",
            "test accuracy: 63.87318446076699 %\n",
            "0.1829335176927781\n",
            "train accuracy: 86.21346754272402 %\n",
            "test accuracy: 64.30390229884672 %\n",
            "0.1632054099482841\n",
            "train accuracy: 87.35797641166434 %\n",
            "test accuracy: 64.53085027362194 %\n",
            "0.1615240879787282\n",
            "train accuracy: 87.56721601348487 %\n",
            "test accuracy: 64.65252818741897 %\n",
            "0.1645238781403066\n",
            "train accuracy: 87.52730707331602 %\n",
            "test accuracy: 64.79152820248913 %\n",
            "0.34615098636102287\n",
            "train accuracy: 80.94808163084141 %\n",
            "test accuracy: 63.03238803704566 %\n",
            "0.16713125846458182\n",
            "train accuracy: 87.27520168444434 %\n",
            "test accuracy: 64.61063966991176 %\n",
            "0.13446760530219481\n",
            "train accuracy: 89.2715302301758 %\n",
            "test accuracy: 65.0321511463665 %\n",
            "0.12767416367012904\n",
            "train accuracy: 89.71986514470353 %\n",
            "test accuracy: 65.14717379295959 %\n",
            "0.1275368377253399\n",
            "train accuracy: 89.78788582467027 %\n",
            "test accuracy: 65.49545520846384 %\n",
            "0.12591723124963983\n",
            "train accuracy: 89.92313298384387 %\n",
            "test accuracy: 65.25131656338665 %\n",
            "0.11324105446996169\n",
            "train accuracy: 90.69461731353093 %\n",
            "test accuracy: 65.37683113058804 %\n",
            "0.22062280247038824\n",
            "train accuracy: 86.51297751985892 %\n",
            "test accuracy: 64.79958868461404 %\n",
            "0.10520417155614993\n",
            "train accuracy: 91.2665316876647 %\n",
            "test accuracy: 65.53922566762995 %\n",
            "0.21142859597654856\n",
            "train accuracy: 86.96056030858429 %\n",
            "test accuracy: 64.97388475417877 %\n",
            "0.09714669780770213\n",
            "train accuracy: 91.82832585696991 %\n",
            "test accuracy: 65.67610577604418 %\n",
            "0.09487960322911239\n",
            "train accuracy: 92.00986368382233 %\n",
            "test accuracy: 65.72616905914703 %\n",
            "0.09368177199620847\n",
            "train accuracy: 92.12547515746189 %\n",
            "test accuracy: 66.14777809912904 %\n",
            "0.08641184043284082\n",
            "train accuracy: 92.60119992557166 %\n",
            "test accuracy: 65.85635616282393 %\n",
            "0.08335611274175321\n",
            "train accuracy: 92.82678186229624 %\n",
            "test accuracy: 65.89788505077938 %\n",
            "0.08020471300045955\n",
            "train accuracy: 93.05697570272692 %\n",
            "test accuracy: 65.92193080711547 %\n",
            "0.07694522610450491\n",
            "train accuracy: 93.29899952498297 %\n",
            "test accuracy: 65.94391477964965 %\n",
            "0.07411750653122319\n",
            "train accuracy: 93.51536363095974 %\n",
            "test accuracy: 65.97530615836823 %\n",
            "0.06984169048844671\n",
            "train accuracy: 93.80881115848373 %\n",
            "test accuracy: 65.95743165292481 %\n",
            "0.06829448443717649\n",
            "train accuracy: 93.95609554284201 %\n",
            "test accuracy: 66.0501403766956 %\n",
            "0.06451964658059622\n",
            "train accuracy: 94.22622325848407 %\n",
            "test accuracy: 66.03927640952128 %\n",
            "0.06255053641151191\n",
            "train accuracy: 94.39541199660104 %\n",
            "test accuracy: 66.11939144072466 %\n",
            "0.06011963965225911\n",
            "train accuracy: 94.58921741729381 %\n",
            "test accuracy: 66.15474417901393 %\n",
            "0.057556466489566215\n",
            "train accuracy: 94.78704296174658 %\n",
            "test accuracy: 66.16913475309775 %\n",
            "0.055414613828292734\n",
            "train accuracy: 94.96051906786732 %\n",
            "test accuracy: 66.20749333675184 %\n",
            "0.053406703501315676\n",
            "train accuracy: 95.12578450273277 %\n",
            "test accuracy: 66.23655820456386 %\n",
            "0.05153435654762343\n",
            "train accuracy: 95.28186098948107 %\n",
            "test accuracy: 66.28398336859772 %\n",
            "0.04980746730726322\n",
            "train accuracy: 95.42879017202795 %\n",
            "test accuracy: 66.33343349969019 %\n",
            "0.0480933900667046\n",
            "train accuracy: 95.57268897780091 %\n",
            "test accuracy: 66.36759914639956 %\n",
            "0.04646126605242522\n",
            "train accuracy: 95.71065589054624 %\n",
            "test accuracy: 66.40021234916709 %\n",
            "0.0449251907458147\n",
            "train accuracy: 95.84104932236927 %\n",
            "test accuracy: 66.43739139656427 %\n",
            "0.04341005061975377\n",
            "train accuracy: 95.96892916234566 %\n",
            "test accuracy: 66.45671927782627 %\n",
            "0.042022062815649526\n",
            "train accuracy: 96.08957144995722 %\n",
            "test accuracy: 66.49313788136965 %\n",
            "0.04068803132628861\n",
            "train accuracy: 96.20395584330026 %\n",
            "test accuracy: 66.5294018978703 %\n",
            "0.03942580160562978\n",
            "train accuracy: 96.3144299726339 %\n",
            "test accuracy: 66.55950419475731 %\n",
            "0.03820480896145428\n",
            "train accuracy: 96.42006777168532 %\n",
            "test accuracy: 66.58861605228022 %\n",
            "0.03704868462404094\n",
            "train accuracy: 96.52196571024852 %\n",
            "test accuracy: 66.61424934303687 %\n",
            "0.035947799861229014\n",
            "train accuracy: 96.61875072170787 %\n",
            "test accuracy: 66.64251239761764 %\n",
            "0.034889546633347014\n",
            "train accuracy: 96.71155516232707 %\n",
            "test accuracy: 66.66733406579418 %\n",
            "0.0338845087146573\n",
            "train accuracy: 96.80112894504882 %\n",
            "test accuracy: 66.69488207590192 %\n",
            "0.03292528805196999\n",
            "train accuracy: 96.88671334549149 %\n",
            "test accuracy: 66.72264584101148 %\n",
            "0.03200381184617228\n",
            "train accuracy: 96.9688042533643 %\n",
            "test accuracy: 66.74661056531292 %\n",
            "0.031126259429735736\n",
            "train accuracy: 97.04759980427642 %\n",
            "test accuracy: 66.77195243130221 %\n",
            "0.030278697077171516\n",
            "train accuracy: 97.12329614609351 %\n",
            "test accuracy: 66.79533825464796 %\n",
            "0.029468188221570463\n",
            "train accuracy: 97.1966256042948 %\n",
            "test accuracy: 66.81320981286825 %\n",
            "0.028696433192171255\n",
            "train accuracy: 97.2667406364153 %\n",
            "test accuracy: 66.84081306617067 %\n",
            "0.027951142495015614\n",
            "train accuracy: 97.33401231753172 %\n",
            "test accuracy: 66.86236073340497 %\n",
            "0.027239351116953033\n",
            "train accuracy: 97.3988290901507 %\n",
            "test accuracy: 66.8846908018877 %\n",
            "0.026551770202480132\n",
            "train accuracy: 97.4612672019783 %\n",
            "test accuracy: 66.90414008703783 %\n",
            "0.025894096857285248\n",
            "train accuracy: 97.52146032148767 %\n",
            "test accuracy: 66.92587207905967 %\n",
            "0.025264983661914316\n",
            "train accuracy: 97.57929441912326 %\n",
            "test accuracy: 66.9467462747003 %\n",
            "0.024658557637919434\n",
            "train accuracy: 97.63481816289934 %\n",
            "test accuracy: 66.9693852489857 %\n",
            "0.02406880154627617\n",
            "train accuracy: 97.68906860063203 %\n",
            "test accuracy: 66.9869720596856 %\n",
            "0.023504478588915523\n",
            "train accuracy: 97.7409346495433 %\n",
            "test accuracy: 67.00342646487395 %\n",
            "0.0229634038762133\n",
            "train accuracy: 97.79100370294626 %\n",
            "test accuracy: 67.02176172837319 %\n",
            "0.02244102277355906\n",
            "train accuracy: 97.83933403946659 %\n",
            "test accuracy: 67.03830536401894 %\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.01\n",
        "net = NeuralNet(x_train.shape[1])\n",
        "for i in range(10000):\n",
        "    loss = net.propagate(x_train, y_train)\n",
        "    net.update(alpha)\n",
        "    if i % 100 == 0:\n",
        "        y_pred_train = net.predict(x_train)\n",
        "        y_pred_test = net.predict(x_test)\n",
        "        print(loss)\n",
        "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100))\n",
        "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_test - y_test)) * 100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
